{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running ollama on Jupyter!\n",
    "\n",
    "Hi! Welcome to my series of simple Jupyer Notebook Code, begginer friendly, and simple to get you started.\n",
    "\n",
    "Follow the simple instructions in each cell, and have fun!\n",
    "\n",
    "### First, you must:\n",
    "\n",
    "1. Download Ollama https://ollama.com/download\n",
    "\n",
    "2. Select a model\n",
    "\n",
    "3. Then propmt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ollama in /Users/douzog/Library/Python/3.9/lib/python/site-packages (0.5.1)\n",
      "Requirement already satisfied: httpx>=0.27 in /Users/douzog/Library/Python/3.9/lib/python/site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: pydantic>=2.9 in /Users/douzog/Library/Python/3.9/lib/python/site-packages (from ollama) (2.11.7)\n",
      "Requirement already satisfied: anyio in /Users/douzog/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27->ollama) (4.4.0)\n",
      "Requirement already satisfied: certifi in /Users/douzog/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27->ollama) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/douzog/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27->ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/douzog/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27->ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in /Users/douzog/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/douzog/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/douzog/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.9->ollama) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/douzog/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/douzog/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.9->ollama) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/douzog/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.9->ollama) (0.4.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/douzog/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.27->ollama) (1.2.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install ollama # comment this line if ollama is already installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test if Ollama was installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models: ['llama3:latest', 'gemma3:4b', 'tinyllama:latest']\n"
     ]
    }
   ],
   "source": [
    "import ollama \n",
    "resp = ollama.list()\n",
    "model_names = [m.model for m in resp.models]\n",
    "print(\"Models:\", model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'gemma3:4b'# select model, google's Gemma3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuction to query Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(prompt):\n",
    "    response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {'role': 'user', 'content': prompt},\n",
    "        ]\n",
    "    )\n",
    "    return print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each cell should give you an individual output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iâ€™m doing well, thank you for asking! As a large language model, I don't really *feel* things, but my systems are running smoothly. ðŸ˜Š \n",
      "\n",
      "How are *you* doing today? \n",
      "\n",
      "Is there anything I can help you with?\n"
     ]
    }
   ],
   "source": [
    "query = \"'Hello, how are you?'\"\n",
    "chat(query) # call chat function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
