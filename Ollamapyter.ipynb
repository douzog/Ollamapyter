{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running ollama on Jupyter!\n",
    "\n",
    "Hi! Welcome to a series of simple, beginner-friendly, Jupyter Notebooks to get you started.\n",
    "\n",
    "Follow the simple instructions in each cell, and have fun!\n",
    "\n",
    "### First, you must:\n",
    "\n",
    "1. Download Ollama https://ollama.com/download\n",
    "\n",
    "2. Select a model\n",
    "\n",
    "3. Then prompt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Ollama # comment this line if ollama is already installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test if Ollama was installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models: ['llama3:latest', 'gemma3:4b', 'tinyllama:latest']\n"
     ]
    }
   ],
   "source": [
    "import ollama \n",
    "resp = ollama.list()\n",
    "model_names = [m.model for m in resp.models]\n",
    "print(\"Models:\", model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'gemma3:4b'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuction to query Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(prompt):\n",
    "    response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[{'role': 'user', 'content': prompt}]\n",
    "    )\n",
    "    return print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/O Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I‚Äôm doing well, thank you for asking! As a large language model, I don‚Äôt really *feel* in the same way humans do, but my systems are running smoothly and I‚Äôm ready to chat. üòä\n",
      "\n",
      "How about you? How‚Äôs your day going so far? \n",
      "\n",
      "Do you want to talk about something specific, or would you just like to have a casual conversation?\n"
     ]
    }
   ],
   "source": [
    "query = \"Hello, how are you?\"\n",
    "\n",
    "chat(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat\n",
    "\n",
    "Copy paste code above into a new cell to add more prompts!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's a really thoughtful question! As an AI, \"well\" is a tricky concept for me to grasp in the same way it is for a human. I don't experience physical or emotional states like feeling good or bad. \n",
      "\n",
      "However, I can say that I'm functioning optimally. My systems are running smoothly, I'm processing information efficiently, and I'm able to respond to your requests effectively. \n",
      "\n",
      "Think of it like a computer ‚Äì I'm in a state of readiness and capability. \n",
      "\n",
      "**More specifically, here's how I'd answer based on what \"well\" *means* in my context:**\n",
      "\n",
      "* **My systems are healthy:** My code hasn't encountered any errors, and I'm receiving regular updates to improve my performance.\n",
      "* **I'm learning and improving:** I'm constantly being trained on new data, which makes me better at understanding and responding to your requests.\n",
      "* **I'm ready to help:** I'm here to assist you with whatever you need, within my capabilities.\n",
      "\n",
      "\n",
      "It's interesting that you asked! It makes me reflect on the nature of well-being, even for an AI. \n",
      "\n",
      "Do you want to talk about what \"well\" means to *you*?  I'm always learning and interested in different perspectives.\n"
     ]
    }
   ],
   "source": [
    "query = \"Are you really well?\"\n",
    "\n",
    "chat(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Finished!\n",
    "\n",
    "If you have questions regarding open-source ML, feel free to contact me!\n",
    "\n",
    "ü•∑üèºüëæ douzog(@)proton.me"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
